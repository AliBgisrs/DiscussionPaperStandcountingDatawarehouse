{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbac3d33-562b-4585-a4be-74c48a1e8a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for small images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c796a6f1-37a8-404f-8fea-d3ad56bfe6c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c016f259-7f23-4dd6-b682-9e28a893277c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for big images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4cc582-6c15-45a0-83bb-c04604b2cb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# 1. Lift the pixel limit for both OpenCV and PIL\n",
    "os.environ[\"OPENCV_IO_MAX_IMAGE_PIXELS\"] = str(2**33) # Set to ~8.5 billion pixels\n",
    "Image.MAX_IMAGE_PIXELS = None # Disable PIL safety limit entirely\n",
    "\n",
    "def to_rgb(img_path, out_path=None):\n",
    "    out_path = out_path or img_path\n",
    "    \n",
    "    try:\n",
    "        # Attempt to read with OpenCV\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "        \n",
    "        # If OpenCV fails or returns None, force use of PIL\n",
    "        if img is None:\n",
    "            raise ValueError(\"OpenCV returned None\")\n",
    "\n",
    "    except Exception:\n",
    "        # Fallback to PIL for massive or problematic files\n",
    "        try:\n",
    "            print(f\"Using PIL fallback for: {os.path.basename(img_path)}\")\n",
    "            with Image.open(img_path) as pill_img:\n",
    "                # Convert to RGB and then to a NumPy array\n",
    "                img_rgb = pill_img.convert('RGB')\n",
    "                img = np.array(img_rgb)\n",
    "                # OpenCV uses BGR, PIL uses RGB, so we swap\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        except Exception as e:\n",
    "            print(f\"FAILED to read {img_path}: {e}\")\n",
    "            return\n",
    "\n",
    "    # Process channels to ensure 3-channel RGB\n",
    "    try:\n",
    "        if img.ndim == 2:  # Grayscale\n",
    "            img = cv2.merge([img, img, img])\n",
    "        elif img.ndim == 3:\n",
    "            if img.shape[2] == 4:  # RGBA\n",
    "                img = img[:, :, :3]\n",
    "            elif img.shape[2] == 3:\n",
    "                pass  # Already RGB\n",
    "            else:\n",
    "                print(f\"Skip (unexpected channels {img.shape[2]}): {img_path}\")\n",
    "                return\n",
    "        \n",
    "        # Save the result\n",
    "        cv2.imwrite(out_path, img)\n",
    "        print(f\"Successfully processed: {os.path.basename(img_path)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during processing/saving {img_path}: {e}\")\n",
    "\n",
    "# --- Configuration ---\n",
    "roots = [\n",
    "    r\"C:\\Users\\bazrafka\\Desktop\\counting\\DiscussionPaperData\\inputiMage\",\n",
    "]\n",
    "exts = (\"*.png\", \"*.jpg\", \"*.jpeg\", \"*.tif\", \"*.tiff\")\n",
    "\n",
    "print(\"Starting processing...\")\n",
    "for root in roots:\n",
    "    for ext in exts:\n",
    "        # Recursive search\n",
    "        files = glob.glob(os.path.join(root, \"**\", ext), recursive=True)\n",
    "        for p in files:\n",
    "            to_rgb(p)\n",
    "\n",
    "print(\"Done: All images have been checked and converted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef8c25e3-5113-46fa-8671-33b6ca93a0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch, torchvision, ultralytics\n",
    "# print(\"Torch:\", torch.__version__)\n",
    "# print(\"TorchVision:\", torchvision.__version__)\n",
    "# print(\"Ultralytics:\", ultralytics.__version__)\n",
    "# print(\"CUDA available:\", torch.cuda.is_available())\n",
    "# if torch.cuda.is_available():\n",
    "#     print(\"GPU:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9641cc80-a227-488a-9b8e-3c3b8163ca46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc41a9cc-9e5e-4131-b4aa-d8c01e2e6b3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f81c010-5db3-492b-8c49-ef8096b770b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting for big images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "38b3c917-04c9-47ec-a0b5-fc5eae438530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading image: C:/Users/bazrafka/Desktop/counting/DiscussionPaperData/inputiMage/Canada24116.png\n",
      "Image Resolution: 20723x18671 (386.92 Million Pixels)\n",
      "Done. Kept 40267 detections. Saved to C:/Users/bazrafka/Desktop/counting/DiscussionPaperData/outputRESULTS/stitched_result.jpg\n"
     ]
    }
   ],
   "source": [
    "import os, math, cv2, numpy as np\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "\n",
    "# 1. CRITICAL: Lift limits for BOTH OpenCV and PIL\n",
    "os.environ[\"OPENCV_IO_MAX_IMAGE_PIXELS\"] = str(2**33)\n",
    "Image.MAX_IMAGE_PIXELS = None \n",
    "\n",
    "# ----------------------------\n",
    "# Config\n",
    "# ----------------------------\n",
    "IMAGE_PATH = r\"C:/Users/bazrafka/Desktop/counting/DiscussionPaperData/inputiMage/Canada24116.png\"\n",
    "MODEL_PATH = r\"C:/Users/bazrafka/Desktop/counting/runs/detect/train14/weights/best.pt\"\n",
    "OUT_IMG    = r\"C:/Users/bazrafka/Desktop/counting/DiscussionPaperData/outputRESULTS/stitched_result.jpg\"\n",
    "\n",
    "TILE_SIZE  = 640          \n",
    "OVERLAP    = 320           \n",
    "IMGSZ      = TILE_SIZE     \n",
    "CONF_TH    = 0.01           \n",
    "IOU_NMS    = 0.2           \n",
    "DRAW_MASKS = True          \n",
    "\n",
    "model = YOLO(MODEL_PATH)\n",
    "\n",
    "# ----------------------------\n",
    "# Utilities\n",
    "# ----------------------------\n",
    "def iter_tiles(w, h, tile, overlap):\n",
    "    stride = max(1, tile - overlap)\n",
    "    xs = list(range(0, max(1, w - tile + 1), stride))\n",
    "    ys = list(range(0, max(1, h - tile + 1), stride))\n",
    "    if xs and xs[-1] + tile < w: xs.append(w - tile)\n",
    "    if ys and ys[-1] + tile < h: ys.append(h - tile)\n",
    "    for y in ys:\n",
    "        for x in xs:\n",
    "            x1, y1 = int(max(0, x)), int(max(0, y))\n",
    "            x2, y2 = int(min(w, x1 + tile)), int(min(h, y1 + tile))\n",
    "            yield x1, y1, x2, y2\n",
    "\n",
    "def box_iou_xyxy(a, b):\n",
    "    xx1 = max(a[0], b[0]); yy1 = max(a[1], b[1])\n",
    "    xx2 = min(a[2], b[2]); yy2 = min(a[3], b[3])\n",
    "    iw = max(0.0, xx2 - xx1); ih = max(0.0, yy2 - yy1)\n",
    "    inter = iw * ih\n",
    "    ua = (a[2]-a[0])*(a[3]-a[1]) + (b[2]-b[0])*(b[3]-b[1]) - inter\n",
    "    return inter / ua if ua > 0 else 0.0\n",
    "\n",
    "def nms_global(dets, iou_thr=0.5):\n",
    "    out = []\n",
    "    dets_by_cls = {}\n",
    "    for d in dets:\n",
    "        dets_by_cls.setdefault(d[\"cls\"], []).append(d)\n",
    "    for c, items in dets_by_cls.items():\n",
    "        items = sorted(items, key=lambda d: d[\"conf\"], reverse=True)\n",
    "        while items:\n",
    "            best = items.pop(0)\n",
    "            out.append(best)\n",
    "            items = [d for d in items if box_iou_xyxy(best[\"xyxy\"], d[\"xyxy\"]) < iou_thr]\n",
    "    return out\n",
    "\n",
    "def draw_global(image_bgr, detections, draw_masks=True):\n",
    "    out = image_bgr.copy()\n",
    "    for d in detections:\n",
    "        x1,y1,x2,y2 = map(int, d[\"xyxy\"])\n",
    "        cv2.rectangle(out, (x1,y1), (x2,y2), (0,255,0), 2)\n",
    "        if draw_masks and d.get(\"polys\"):\n",
    "            for poly in d[\"polys\"]:\n",
    "                if poly is not None and len(poly) > 0:\n",
    "                    pts = np.round(poly).astype(np.int32).reshape(-1,1,2)\n",
    "                    cv2.polylines(out, [pts], isClosed=True, color=(255,0,0), thickness=1)\n",
    "    return out\n",
    "\n",
    "# ----------------------------\n",
    "# Pipeline (Modified for Large Images)\n",
    "# ----------------------------\n",
    "\n",
    "print(f\"Loading image: {IMAGE_PATH}\")\n",
    "try:\n",
    "    # Use PIL to load the image instead of cv2.imread\n",
    "    with Image.open(IMAGE_PATH) as pil_img:\n",
    "        # Convert to RGB then to BGR (OpenCV format)\n",
    "        img = cv2.cvtColor(np.array(pil_img.convert(\"RGB\")), cv2.COLOR_RGB2BGR)\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Failed to load massive image with PIL: {e}\")\n",
    "\n",
    "H, W = img.shape[:2]\n",
    "print(f\"Image Resolution: {W}x{H} ({ (W*H)/1e6 :.2f} Million Pixels)\")\n",
    "\n",
    "global_dets = []\n",
    "\n",
    "for x1,y1,x2,y2 in iter_tiles(W, H, TILE_SIZE, OVERLAP):\n",
    "    tile = img[y1:y2, x1:x2]\n",
    "    res = model.predict(tile, imgsz=IMGSZ, conf=CONF_TH, verbose=False)\n",
    "    if not res: continue\n",
    "    r = res[0]\n",
    "\n",
    "    if getattr(r, \"boxes\", None) is not None and len(r.boxes) > 0:\n",
    "        masks = r.masks.xy if getattr(r, \"masks\", None) is not None else None\n",
    "\n",
    "        for i in range(len(r.boxes)):\n",
    "            cls  = int(r.boxes.cls[i].item())\n",
    "            conf = float(r.boxes.conf[i].item())\n",
    "            xyxy = r.boxes.xyxy[i].detach().cpu().numpy()\n",
    "            g_xyxy = xyxy + np.array([x1, y1, x1, y1], dtype=np.float32)\n",
    "\n",
    "            polys_glob = None\n",
    "            if masks is not None:\n",
    "                try:\n",
    "                    polys_tile = masks[i]\n",
    "                    polys_glob = [p + np.array([x1, y1], dtype=np.float32) for p in polys_tile]\n",
    "                except: polys_glob = None\n",
    "\n",
    "            global_dets.append({\n",
    "                \"cls\": cls, \"conf\": conf, \"xyxy\": g_xyxy.astype(float), \"polys\": polys_glob\n",
    "            })\n",
    "\n",
    "global_dets = nms_global(global_dets, iou_thr=IOU_NMS)\n",
    "vis = draw_global(img, global_dets, draw_masks=DRAW_MASKS)\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(os.path.dirname(OUT_IMG), exist_ok=True)\n",
    "cv2.imwrite(OUT_IMG, vis)\n",
    "\n",
    "print(f\"Done. Kept {len(global_dets)} detections. Saved to {OUT_IMG}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "db22b90c-a46e-406e-b17f-b130a1aa727d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export shapes (Shapefile / GDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eb1f3661-05ba-41d3-9122-115626fe19f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Shapefile written: C:\\Users\\bazrafka\\Desktop\\counting\\DiscussionPaperData\\outputRESULTS\\detections_boxes.shp\n",
      "[SKIP] FileGDB export skipped (arcpy not available).\n",
      "Tiles processed. Global detections kept: 40267\n",
      "Saved visualization: C:/Users/bazrafka/Desktop/counting/DiscussionPaperData/outputRESULTS/stitched_result.jpg\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Export shapes (Shapefile / GDB)\n",
    "# ============================\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "OUTPUT_DIR = Path(r\"C:/Users/bazrafka/Desktop/counting/DiscussionPaperData/outputRESULTS\")  # change if needed\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUT_SHP = OUTPUT_DIR / \"detections_boxes.shp\"               # Shapefile\n",
    "OUT_GDB = OUTPUT_DIR / \"detections.gdb\"                     # File Geodatabase (optional if arcpy available)\n",
    "FC_NAME = \"boxes\"                                           # feature class name inside GDB\n",
    "\n",
    "# ---- Try optional GIS modules ----\n",
    "try:\n",
    "    import geopandas as gpd\n",
    "    from shapely.geometry import Polygon\n",
    "    _HAS_GPD = True\n",
    "except Exception as e:\n",
    "    _HAS_GPD = False\n",
    "    print(\"[WARN] geopandas/shapely not available -> Shapefile export will be skipped.\", e)\n",
    "\n",
    "try:\n",
    "    import rasterio\n",
    "    _HAS_RIO = True\n",
    "except Exception:\n",
    "    _HAS_RIO = False\n",
    "\n",
    "try:\n",
    "    import arcpy\n",
    "    _HAS_ARCPY = True\n",
    "except Exception:\n",
    "    _HAS_ARCPY = False\n",
    "\n",
    "# ---- Helper: pixel -> map coords if image is georeferenced ----\n",
    "def _get_geo_context(image_path):\n",
    "    \"\"\"Return (transform, crs) or (None, None) if not available.\"\"\"\n",
    "    if not _HAS_RIO:\n",
    "        return None, None\n",
    "    try:\n",
    "        with rasterio.open(image_path) as src:\n",
    "            # Some JPEGs may have no CRS/transform; handle that\n",
    "            transform = src.transform if src.transform is not None else None\n",
    "            crs = src.crs if src.crs is not None else None\n",
    "            # Identify uninitialized transform (common for plain JPEGs)\n",
    "            if transform is not None and (transform.a == 1 and transform.e == -1 and transform.c == 0 and transform.f == 0):\n",
    "                # Heuristic: this often indicates pixel space with flipped y\n",
    "                # Treat as not-georeferenced for safety\n",
    "                return None, None\n",
    "            return transform, crs\n",
    "    except Exception:\n",
    "        return None, None\n",
    "\n",
    "def _px_to_map_box(x1, y1, x2, y2, transform):\n",
    "    \"\"\"Return polygon coords in map units using rasterio Affine transform.\"\"\"\n",
    "    # Corner mapping: (col,row) -> (x,y)\n",
    "    # Note: y is row, x is col in image terms\n",
    "    from affine import Affine\n",
    "    assert isinstance(transform, Affine)\n",
    "    # Four corners in pixel space\n",
    "    pts_px = [(x1, y1), (x2, y1), (x2, y2), (x1, y2)]\n",
    "    # Convert each (col,row) to (X,Y)\n",
    "    pts_map = [transform * (px, py) for (px, py) in pts_px]\n",
    "    return pts_map\n",
    "\n",
    "# ---- Build GeoDataFrame rows ----\n",
    "def _build_records(detections, transform=None, class_names=None):\n",
    "    \"\"\"Return list of dicts with geometry + attributes.\"\"\"\n",
    "    recs = []\n",
    "    for i, d in enumerate(detections, 1):\n",
    "        x1, y1, x2, y2 = map(float, d[\"xyxy\"])\n",
    "        w = max(0.0, x2 - x1)\n",
    "        h = max(0.0, y2 - y1)\n",
    "        area_px = w * h\n",
    "        cls_id = int(d[\"cls\"])\n",
    "        name = class_names.get(cls_id, str(cls_id)) if class_names else str(cls_id)\n",
    "        conf = float(d[\"conf\"])\n",
    "\n",
    "        if transform is not None:\n",
    "            try:\n",
    "                ring = _px_to_map_box(x1, y1, x2, y2, transform)\n",
    "            except Exception:\n",
    "                # Fallback to pixel coords if transform fails\n",
    "                ring = [(x1, y1), (x2, y1), (x2, y2), (x1, y2)]\n",
    "        else:\n",
    "            ring = [(x1, y1), (x2, y1), (x2, y2), (x1, y2)]\n",
    "\n",
    "        recs.append({\n",
    "            \"id\": i,\n",
    "            \"cls\": cls_id,\n",
    "            \"class_name\": name,\n",
    "            \"conf\": conf,\n",
    "            \"x1\": x1, \"y1\": y1, \"x2\": x2, \"y2\": y2,\n",
    "            \"width\": w, \"height\": h, \"area_px\": area_px,\n",
    "            \"geometry\": Polygon(ring) if _HAS_GPD else None\n",
    "        })\n",
    "    return recs\n",
    "\n",
    "# ---- Prepare class name mapping from the model (if available) ----\n",
    "CLASS_NAMES = None\n",
    "try:\n",
    "    # Ultralytics models expose names as a dict {id: \"name\"}\n",
    "    CLASS_NAMES = model.model.names if hasattr(model, \"model\") else model.names\n",
    "except Exception:\n",
    "    CLASS_NAMES = None\n",
    "\n",
    "# ---- Read geo context from input image ----\n",
    "rio_transform, rio_crs = _get_geo_context(IMAGE_PATH)\n",
    "\n",
    "# ---- Build records ----\n",
    "records = _build_records(global_dets, transform=rio_transform, class_names=CLASS_NAMES)\n",
    "\n",
    "# ---- Export Shapefile via GeoPandas ----\n",
    "if _HAS_GPD:\n",
    "    gdf = gpd.GeoDataFrame(records, geometry=\"geometry\", crs=rio_crs)  # crs=None if not georef'd\n",
    "    # If not georeferenced, you can leave CRS unset; shapefile will be created without .prj\n",
    "    # If you prefer to tag pixel space, omit setting a fake CRS to avoid confusion.\n",
    "    if OUT_SHP.exists():\n",
    "        OUT_SHP.unlink()  # remove stale file so drivers don't complain about schema changes\n",
    "    # Driver chosen by extension (.shp)\n",
    "    gdf.to_file(OUT_SHP)\n",
    "    print(f\"[OK] Shapefile written: {OUT_SHP}\")\n",
    "else:\n",
    "    print(\"[SKIP] Shapefile export skipped (install geopandas + shapely + fiona).\")\n",
    "\n",
    "# ---- Optional: Export to File Geodatabase via arcpy (if available) ----\n",
    "if _HAS_ARCPY:\n",
    "    try:\n",
    "        # Create GDB if missing\n",
    "        if not OUT_GDB.exists():\n",
    "            arcpy.management.CreateFileGDB(str(OUTPUT_DIR), OUT_GDB.name)\n",
    "        # Delete FC if exists\n",
    "        fc_path = str(OUT_GDB / FC_NAME)\n",
    "        if arcpy.Exists(fc_path):\n",
    "            arcpy.management.Delete(fc_path)\n",
    "\n",
    "        # Spatial reference\n",
    "        if rio_crs:\n",
    "            # Convert rasterio CRS to WKT and feed to arcpy\n",
    "            sr = arcpy.SpatialReference()\n",
    "            sr.loadFromString(rio_crs.to_wkt())\n",
    "        else:\n",
    "            sr = arcpy.SpatialReference(0)  # Unknown\n",
    "\n",
    "        # Create feature class (POLYGON)\n",
    "        arcpy.management.CreateFeatureclass(str(OUT_GDB), FC_NAME, \"POLYGON\", spatial_reference=sr)\n",
    "\n",
    "        # Add fields (keep names <= 10 chars for shapefile, but GDB is flexible; still keep tidy)\n",
    "        fld_specs = [\n",
    "            (\"id\", \"LONG\"),\n",
    "            (\"cls\", \"LONG\"),\n",
    "            (\"cls_name\", \"TEXT\", 64),\n",
    "            (\"conf\", \"DOUBLE\"),\n",
    "            (\"x1\", \"DOUBLE\"), (\"y1\", \"DOUBLE\"), (\"x2\", \"DOUBLE\"), (\"y2\", \"DOUBLE\"),\n",
    "            (\"width\", \"DOUBLE\"), (\"height\", \"DOUBLE\"), (\"area_px\", \"DOUBLE\"),\n",
    "        ]\n",
    "        for name, ftype, *rest in fld_specs:\n",
    "            length = rest[0] if rest else None\n",
    "            if ftype == \"TEXT\" and length:\n",
    "                arcpy.management.AddField(fc_path, name, ftype, field_length=length)\n",
    "            else:\n",
    "                arcpy.management.AddField(fc_path, name, ftype)\n",
    "\n",
    "        # Insert rows\n",
    "        with arcpy.da.InsertCursor(fc_path,\n",
    "                                   [\"SHAPE@\",\n",
    "                                    \"id\",\"cls\",\"cls_name\",\"conf\",\n",
    "                                    \"x1\",\"y1\",\"x2\",\"y2\",\"width\",\"height\",\"area_px\"]) as cur:\n",
    "            for rec in records:\n",
    "                # Build polygon geometry\n",
    "                ring = rec[\"geometry\"].exterior.coords[:] if rec.get(\"geometry\") is not None else [\n",
    "                    (rec[\"x1\"], rec[\"y1\"]),\n",
    "                    (rec[\"x2\"], rec[\"y1\"]),\n",
    "                    (rec[\"x2\"], rec[\"y2\"]),\n",
    "                    (rec[\"x1\"], rec[\"y2\"]),\n",
    "                    (rec[\"x1\"], rec[\"y2\"])  # close ring\n",
    "                ]\n",
    "                array = arcpy.Array([arcpy.Point(x, y) for (x, y) in ring])\n",
    "                poly = arcpy.Polygon(array, sr)\n",
    "                cur.insertRow([poly,\n",
    "                               rec[\"id\"], rec[\"cls\"], rec[\"class_name\"], rec[\"conf\"],\n",
    "                               rec[\"x1\"], rec[\"y1\"], rec[\"x2\"], rec[\"y2\"],\n",
    "                               rec[\"width\"], rec[\"height\"], rec[\"area_px\"]])\n",
    "        print(f\"[OK] FileGDB feature class written: {fc_path}\")\n",
    "    except Exception as e:\n",
    "        print(\"[WARN] GDB export failed:\", e)\n",
    "else:\n",
    "    print(\"[SKIP] FileGDB export skipped (arcpy not available).\")\n",
    "\n",
    "print(f\"Tiles processed. Global detections kept: {len(global_dets)}\")\n",
    "print(f\"Saved visualization: {OUT_IMG}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07014f3-64a7-4a5b-94d3-b002b89e697c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0b13a5-b6ad-4bf6-a08e-815d2f31ec7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e956d151-dd4c-43ba-847d-13b33b8f357b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562a3b8b-42da-4b4d-8475-d9c5890b5096",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121cae09-0383-40c9-a784-a07990eba10e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7af86d-5f55-4035-a9c8-834b3ff9f043",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159833cb-d6be-4fc8-a5b6-dbb8ee94eb4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (yoloseg)",
   "language": "python",
   "name": "yoloseg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
